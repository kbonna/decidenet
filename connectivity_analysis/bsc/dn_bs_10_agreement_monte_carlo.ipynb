{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "otherwise-collectible",
   "metadata": {},
   "source": [
    "# Null distribution of agreement between LSNs\n",
    "\n",
    "Here, agreement matrices are calculated for data driven community partitions. Agreement matrix in an n-by-n matrix calculated for the set of community partitions (this set can also contain single partition). An element of the agreement matrix $D_{ij}$ indicated how many times nodes $i$ and $j$ were placed within the same community. If the input set of partitions consist of single partition, agreement can be either 0 (indicating that nodes are not a part of the same community) or 1 (indicating that both nodes share the same community). Agreement matrix can be summarized by calculating block means over reference communities. This procedure decreases the size of agreement matrix from $N_{roi}\\times N_{roi}$ to $N_{networks}\\times N_{networks}$, where $N_{networks}$ is number of referecence communities. \n",
    "\n",
    "Block mean agreement matrix, called LSN agreement, stored in `d_networks` variable indicates for every pair of communities **what is the probability that two randomly selected ROIs (one from the first community and another from the second community) will be placed within the same data-driven community**. Diagonal elements of `d_networks` matrix reflects how stable is given community, with the value of 1 indicating that any two ROIs from that are part of the same data-driven communtiy. In other words, that means that in data-driven community structure such community exists that it at least includes all ROIs from reference community. Off-diagonal elements of `d_networks` matrix reflects tendency for two reference communities to be placed within the same data-driven community. High agreement values indicate increased communication or similarity between communities.    \n",
    "\n",
    "In order to test whether LSN agreement differs between task conditions Monte Carlo strategy for testing significance can be employed. This strategy requires creating null distribution of statistical test of interest. To achieve that entire procedure consisting of agreement calculation and block mean over LSNs is repeated `n_nulls` number of times for reshuffled individual community vectors. Reshuffling preserve basic modular characteristics like number of modules and size of communities but is independent from underlying connectivity (random). This null distribution of LSN agreement can be then used to nonparametrically test significance of statistical tests performed on values from `d_networks`. Null values are stored in `d_networks_null` variable.\n",
    "\n",
    "Array sizes:\n",
    "- `d_networks`: $N_{subjects}\\times N_{conditions}\\times N_{PE\\ signs}\\times N_{networks}\\times N_{networks}$\n",
    "- `d_networks_null`: $N_{reps}\\times N_{subjects}\\times N_{conditions}\\times N_{PE\\ signs}\\times N_{networks}\\times N_{networks}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attached-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dn_utils.networks import agreement_networks\n",
    "from dn_utils.path import path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-world",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "utility-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = \"combined_roi_4and5\"\n",
    "\n",
    "n_nulls = 10_000\n",
    "gamma_range = np.arange(0.5, 2.5, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "useful-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correlation matrices and metadata\n",
    "path_corrmats = join(path[\"bsc\"], \"corrmats\")\n",
    "with open(join(path_corrmats, atlas, \"corrmats_aggregated.json\"), \"r\") as f:\n",
    "    corrmats_meta = json.loads(f.read()) \n",
    "\n",
    "# Load ROI information\n",
    "df_roi = pd.read_csv(\n",
    "    join(path_corrmats, atlas, \"roi_table_filtered.csv\"), index_col=0)\n",
    "df_roi = df_roi.reset_index()\n",
    "\n",
    "n_subjects = len(corrmats_meta[\"dim1\"])\n",
    "n_conditions = len(corrmats_meta[\"dim2\"])\n",
    "n_perr_sign = len(corrmats_meta[\"dim3\"])\n",
    "n_rois = len(corrmats_meta[\"dim4\"])\n",
    "n_nets = len(df_roi[\"netName\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "original-venice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference communities:\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "network_names = df_roi[\"netName\"].unique() \n",
    "network_mapping = {net: i for i, net in enumerate(network_names)}\n",
    "\n",
    "networks = np.array(df_roi[\"netName\"].map(network_mapping))\n",
    "networks_unique = network_mapping.values()\n",
    "print(\"Reference communities:\\n\", networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-genre",
   "metadata": {},
   "source": [
    "### Randomize networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identified-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γ = 0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2ed07ff5be4fe28881a69503242107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γ = 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07358ed8b0d14f0c86030b0cc361d44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γ = 1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbbc725540c43f8a5197613d2cff08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "γ = 2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201cf72b692f4da9ae74ac66e115fe7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for gamma in gamma_range:\n",
    "    print(f\"γ = {gamma}\")\n",
    "\n",
    "    gamma_str = str(float(gamma)).replace('.', '_')\n",
    "    path_graph = join(path_corrmats, atlas, \"unthr\", f\"gamma_{gamma_str}\")\n",
    "\n",
    "    # Load graph metrics\n",
    "    m_aggregated = np.load(join(path_graph, \"m_aggregated.npy\"))\n",
    "    q_aggregated = np.load(join(path_graph, \"q_aggregated.npy\"))\n",
    "    n_subjects, n_conditions, n_perr_sign, n_roi = m_aggregated.shape\n",
    "\n",
    "    d = np.zeros((n_subjects, n_conditions, n_perr_sign, n_roi, n_roi))\n",
    "    d_networks = np.zeros((n_subjects, n_conditions, n_perr_sign, n_nets, n_nets))\n",
    "    d_networks_null = np.zeros((n_nulls, ) + d_networks.shape)\n",
    "\n",
    "    network_names = list(df_roi[\"netName\"].unique())\n",
    "\n",
    "    for sub_idx in tqdm(range(n_subjects)):\n",
    "        for con_idx in range(n_conditions):\n",
    "            for perr_sign_idx in range(n_perr_sign):\n",
    "\n",
    "                m = m_aggregated[sub_idx, con_idx, perr_sign_idx]\n",
    "                \n",
    "                # Agreement averaged over LSN pairs\n",
    "                d_networks[sub_idx, con_idx, perr_sign_idx] = \\\n",
    "                    agreement_networks(m, networks, networks_unique)\n",
    "\n",
    "                # Monte Carlo null distribution of averaged agreement\n",
    "                for rep in range(n_nulls):\n",
    "                    np.random.shuffle(m)\n",
    "                    d_networks_null[rep, sub_idx, con_idx, perr_sign_idx] = \\\n",
    "                        agreement_networks(m, networks, networks_unique)\n",
    "                    \n",
    "    np.save(join(path_graph, \"d_networks_null.npy\"), d_networks_null)\n",
    "    np.save(join(path_graph, \"d_networks.npy\"), d_networks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
